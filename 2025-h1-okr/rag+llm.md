基于 RAG + LLM 的自动化黑盒测试
背景
自动化黑盒测试的难点
●https://doc.weixin.qq.com/doc/w3_AM8APgaIAE0EjjgLCoeTT2R93pWcN?scode=AJEAIQdfAAoJzFB6HjAM8APgaIAE0 
●https://doc.weixin.qq.com/doc/w3_ALQAHQYvACogKueDPclSHeEG0UlEt?scode=AJEAIQdfAAoJKWQJAGALQAHQYvACo 
在过去的方案中遇到比较困难的问题无法很好通过传统技术方法解决
●基于代码，组件入参，api 文档等信息生成巨大的元数据
●基于半自动的方式生成元数据之后，需要进行较为复杂的手动微调
●以上困难对推广与大规模使用带来不便
自动化黑盒测试相关原理以及设计在过去的文档（包括上面两篇）已经有相对详尽的阐述，本文主要针对 RAG + LLM 生成元数据流程的设计进行阐述。
AI Editor 的启示
目前已有的 AI Editor（cursor，trae等）逐步具备基于代码仓库回答问题的能力，并且回答的质量也算不错，基本能找到相关联的代码文件作为上下文进行提问。但目前这些 AI Editor 并不是都依赖本地搭建 RAG（会比较慢） 进行回答，所以如果有更详尽的 RAG 供 LLM 参考，回答的效果可能会更好。
下面是一个简单的尝试记录 https://doc.weixin.qq.com/doc/w3_AM8APgaIAE0Zufsfw43TSiVg3Zbnd?scode=AJEAIQdfAAodu0IfTCAM8APgaIAE0&isEnterEdit=1 
目标
定量目标
●建立基于仓库理解的本地 RAG + LLM 工具流
○利用 LLM 对代码进行分析理解
○基于代码理解构建 RAG
○LLM 对话接口调用 RAG 回答问题
○多轮对话优化元数据生成效果
●在自动化黑盒测试中整合元数据生成流程
○利用 RAG + LLM 生成所有组件以及关键页面的元数据
○设计元数据生成时机与迭代的流程
●继续完善自动化黑盒测试流程
○整合流水线
○接入流程简化与抽象
●文档与专利沉淀
定性目标
●减轻元数据生成的压力，能够以相对自动且快速的方式生成仓库组件与页面的元数据
●自动化黑盒测试能投入生产，真正能起到检测组件问题的作用
●RAG + LLM 工作流能应用到其他项目中，成为仓库理解的关键组成部分
方案设计
概述
整体方案是搭建一个基于代码仓库的 RAG + LLM 流程，用于理解仓库代码，并且给出组件（页面）元数据。
所以生成元数据分成以下步骤
●基于代码仓库生成解释文档
●基于解释文档构建 RAG
●设计 prompt 让 LLM 基于 RAG 生成组件元数据
●自动调优闭环
其中每个步骤都能有不少方案上的选择与取舍，这个在下面分点阐述。
整体架构
由于这个方案主要是为自动化黑盒测试里生成元数据的环节而服务的，所以这个方案也可以看成是自动化黑盒测试里的一个模块。

实际落地的时候，不会在测试的时候再生成元数据，而是在开发流程中的某些时机（合并代码，发布测试环境等）进行统一生成，这样的运行时就可以直接使用生成的元数据了。
RAG + LLM 的整体架构图如下所示。红色流程是提问流程，蓝色流程是回答流程。

提问是事先构造好的 prompt，用于询问组件（页面）对应的输入元数据，而回答则是该组件（页面）的元数据。
整个问答流程也可以进行多轮优化，最后得到相对可用的元数据。

而整个流程的主要环节及组件可以拆分为
●基于代码仓库构建 RAG
●使用 RAG 回答问题
●多轮问答优化
●prompt 设计
组件设计
下面给出初步的组件设计，理论上每个环节使用到的技术都需要进行探究以及尝试，使用到的模型也可以灵活替换，所以不用执着于本方案使用的模型，这些选择不代表最终的选择。
基于代码仓库构建 RAG
要让 LLM 生成正确（有质量保证）的元数据，前提是让 LLM 理解代码。由于 LLM 有输入长度上限，所以如何向 LLM 提供尽量准确以及精细的上下文尤为重要。在 RAG 概念下，RAG 成为了 LLM 上下文信息的一个补充。
解释代码
对于现成代码仓库来说，要求代码仓库有一个对应的文档库实在非常严苛，毕竟没有人会在写代码的时候，同时写上一堆解释代码的文档，而 coder 模型，刚好可以胜任这个任务。我们可以先通过 coder 模型对代码仓库进行解释。

通过 coder LLM 解释代码仓库，最终可以得到一个目录结构与原仓库一致的解释文档目录。
def explain_codebase(repo_path):
    for root, dirs, files in os.walk(repo_path):
        # 过滤无关目录
        if any(filter_folder in dirs for f in filter_folders):
            continue

        for file in files:
            file_path = os.path.join(root, file)
            # 使用 coder LLM 解释文件
            explain_file(file_path)

上面伪代码简单给出了解释仓库的过程，只是遍历文件并交给 coder LLM 解释，需要注意的是解释文本存储的时候，使用代码文件对应路径加上 `.explain` 后缀。
构建 RAG
RAG 的关键是将文档嵌入（embedding），然后持久化到向量数据库中。

这部分流程并不难，其中 embedding 可选各种 embedding 模型，vector database 也可以使用各种开源库。下面的选择是跑通流程所使用的最基础的选择。
●embedding 模型使用 `all-MiniLM-L6-v2`
●vector database 使用 faiss
由于对解释文档进行索引是一个固定的行为，所以解释并且索引结束之后，可以将结果持久化，所以这个流程需要加入持久化模块。
使用 RAG 回答问题
回答问题的时候，需要根据问题将相关性最高的代码片段以及代码解释找出来，统一作为上下文传给 coder LLM 作为参考。
通用回答流程
由于解释文档已经 embedding，所以可以根据向量的相似性进行寻找，一般向量数据库也提供了这样的能力。
下面是是使用 RAG 回答问题的流程图。

需要注意的是，embedding 只是为了将内容转化为向量来求相似性，但 LLM 的输入是文本，所以在找出相似性之后，需要将 embedding 转化回文本。因为构建 RAG 使用的 embedding 与 LLM 的 embedding 不同，所以不能直接透传。
下面是上述令流程的伪代码，方法调用隐藏的细节，其实都是可以探究以及替换的部件，在此不展开描述。
def ask_with_rag(prompt, model, index, k=10):
    relevant_snippets = retrieve_relevant_explanations(prompt, model, index, k=k)
    top_k_snippets = sort_snippets(relevant_snippets)
    prompt = ASK_PROMPT(prompt, top_k_snippets)
    answer = ask_llm(prompt)
    return answer   

获取组件元数据
上面描述的是通用 RAG 流程，但在自动化黑盒测试中，关键的目标是靠这个流程来获取组件 / 页面的元数据。
直接获得元数据比较困难，但是获得 mock 数据相对简单，所以解决这个问题的思路是先让 LLM 给出质量较高的 mock 数据，再根据 mock 数据生成元数据。后者是确定性到确定性，回答会相对可控并且质量更高。

上图是通过 RAG + LLM 获取组件元数据的流程，中间部分可以通过多轮对话获得更为优质的 mock 数据，这样的 mock 数据能生成更好的 schema 元数据。最后生成的 schema 元数据会持久化到自动化黑盒流程里。
多轮问答优化
如果希望做到多轮问答优化，需要有执行效果以及效果的评判。多轮问答有两个方向：
1.通过生成的 mock 数据尝试渲染组件，用渲染效果来评判 mock 质量。
2.通过生成的 mock 数据尝试渲染组件，用该组件的代码覆盖率来评判 mock 质量。
prompt 设计
整个 RAG + LLM 环节涉及到了不少的 prompt，理论上每个 prompt 都需要单独进行设计。
●mock prompt：通过组件及关联代码，要求 LLM 生成 mock 数据。
●schema prompt：通过 mock 数据（可能是多个），要求 LLM 生成元数据。
●generator prompt：通过元数据，要求 LLM 生成对应的数据生成器。
业务应用方向
下面简述一些本方向可以赋能的业务方向。
自动化黑盒测试
本方案的目标本来就是为自动化黑盒测试生成元数据，所以这个流程可以被应用在自动化黑盒测试里。为组件生成元数据，让自动化黑盒测试的元数据及人工微调流程更为便捷。

项目分析理解与组件可视化
对于现有项目来说，组件数量规模庞大，对于不熟悉（甚至熟悉）项目的同学来说，会有以下问题：
●需要预览组件的时候非常困难，需要运行项目，寻找组件存在的页面，构造页面数据，渲染组件。
●需要预览组件的某一个状态非常困难，需要搞清楚逻辑之后 mock 对应状态的数据，才能渲染出组件的对应状态。
●迭代的时候需要清楚了解组件的所有状态，此时也会遇到上面的问题。
通过本流程，可以让 AI 直接构造组件不同状态下的 mock 数据，可以根据需要选择持久化这些 mock 数据，从而解决上面提到的问题。

智能问答
考虑到长期使用闭源 cursor 或者 trae 会有安全风险问题，自己掌握这种技术以及流程可以让我们在 AI Editor 使用上有更多的选择，不至于在后面无法使用这些工具手足无措。

里程碑
下面按月度定里程碑，一方面因为方案中有不少需要探索的环节，时间不方便确定；另一方面因为人力问题，每周不一定有明显的进展。
2025-03-31
这阶段主要工作为工程建设，流程搭建，实现以下事项。
基础流程跑通，包括交互 Agent，RAG，LLM 调用
基础 prompt 设计，可以通过 prompt 限制 LLM 输出为格式化 json，提供 mock 数据以及解释说明
实现基于 mock 数据的组件渲染器
2025-04-30
这阶段主要工作是提升生成的 mock 数据与元数据质量。
更细致的 prompt 设计，mock prompt，schema prompt，generator prompt
元数据微调，元数据持久化
2025-05-31
这阶段主要工作是针对 RAG+LLM 与自动化黑盒流程的整合
生成器整合至自动化黑盒流程
代码变更流程
2025-06-30
这阶段主要工作是针对 AI 闭环多轮优化结果的探索与实现
在渲染器内实现代码覆盖率统计
AI 闭环逻辑

